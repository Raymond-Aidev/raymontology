# NLP íŒŒì‹± ì—”ì§„ ì„±ëŠ¥ ê°€ì´ë“œ

Railway í™˜ê²½ì—ì„œ ì‚¬ì—…ë³´ê³ ì„œ NLP íŒŒì‹± ì‹œìŠ¤í…œ ìµœì í™”

---

## ğŸ“‹ ì‹œìŠ¤í…œ ê°œìš”

### íŒŒì‹± íŒŒì´í”„ë¼ì¸

```
PDF íŒŒì¼
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ (PyMuPDF)           â”‚
â”‚    - í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ               â”‚
â”‚    - ë©”íƒ€ë°ì´í„° ì¶”ì¶œ                    â”‚
â”‚    - OCR í•„ìš” ì‹œ ì²˜ë¦¬ (ì„ íƒ)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. ì„¹ì…˜ ë¶„í•  (Section Parser)          â”‚
â”‚    - ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ë§¤ì¹­               â”‚
â”‚    - ì£¼ìš” ì„¹ì…˜ ì¶”ì¶œ                     â”‚
â”‚    - ê³„ì¸µ êµ¬ì¡° íŒŒì‹±                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ê°œì²´ëª… ì¶”ì¶œ (NER Extractor)         â”‚
â”‚    - ì„ì› ì •ë³´                          â”‚
â”‚    - ê¸ˆì•¡ ì •ë³´                          â”‚
â”‚    - ë‚ ì§œ ì •ë³´                          â”‚
â”‚    - ê´€ê³„ì‚¬ ì •ë³´                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. êµ¬ì¡°í™”ëœ ë°ì´í„°                      â”‚
â”‚    - JSON í˜•ì‹                          â”‚
â”‚    - PostgreSQL ì €ì¥                    â”‚
â”‚    - Neo4j ê·¸ë˜í”„ ìƒì„±                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ Railway í™˜ê²½ ìµœì í™”

### 1. ë©”ëª¨ë¦¬ ê´€ë¦¬

#### ë¬¸ì œ: ëŒ€ìš©ëŸ‰ PDF ì²˜ë¦¬ ì‹œ OOM

**ì¦ìƒ**:
- Railway ìë™ ì¬ì‹œì‘
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ > 450MB

**í•´ê²°ì±…**:

```python
# âŒ ì „ì²´ ë¡œë“œ (ë©”ëª¨ë¦¬ í­ë°œ)
with open('report.pdf', 'rb') as f:
    pdf_data = f.read()  # 100MB PDF â†’ ë©”ëª¨ë¦¬ 100MB+
    text = extract_text(pdf_data)  # ì¶”ê°€ 100MB+
    # ì´ 200MB+

# âœ… ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
from app.nlp.pdf_utils import extract_text_streaming

async for page_data in extract_text_streaming(pdf_path, chunk_size=10):
    # 10í˜ì´ì§€ì”© ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ~10MB)
    await process_page(page_data)
    # ë©”ëª¨ë¦¬ í•´ì œ
```

#### PDF í¬ê¸°ë³„ ì „ëµ

```python
from app.nlp.pdf_utils import estimate_pdf_size

info = estimate_pdf_size(pdf_path)

if info['should_use_streaming']:
    # ëŒ€ìš©ëŸ‰ PDF (>100MB ì˜ˆìƒ)
    async for chunk in extract_text_streaming(
        pdf_path,
        chunk_size=info['recommended_chunk_size']
    ):
        await process_chunk(chunk)
else:
    # ì¼ë°˜ PDF (<100MB ì˜ˆìƒ)
    result = await pdf_extractor.extract_text(pdf_path)
```

### 2. OCR ì‚¬ìš© ì£¼ì˜

**Railway Hobby Planì—ì„œ OCR ë¹„í™œì„±í™” ê¶Œì¥**

```python
# âŒ OCR í™œì„±í™” (ë©”ëª¨ë¦¬ í­ë°œ)
extractor = PDFExtractor(use_ocr=True)  # Tesseract ë©”ëª¨ë¦¬ ê³¼ë‹¤ ì‚¬ìš©

# âœ… OCR ë¹„í™œì„±í™” (Railway ê¶Œì¥)
extractor = PDFExtractor(use_ocr=False)  # PyMuPDFë§Œ ì‚¬ìš©
```

**OCRì´ í•„ìš”í•œ ê²½ìš°**:
1. ë¡œì»¬ì—ì„œ ì‚¬ì „ ì²˜ë¦¬
2. ë³„ë„ OCR ì„œë¹„ìŠ¤ ì‚¬ìš© (Google Vision API ë“±)
3. Railway Pro í”Œëœ ì‚¬ìš© (ë” ë§ì€ ë©”ëª¨ë¦¬)

### 3. ë°°ì¹˜ ì²˜ë¦¬

```python
# ì—¬ëŸ¬ PDF íŒŒì‹± ì‹œ
from app.utils.streaming import process_in_batches

pdfs = list_all_pdfs()  # 1000ê°œ

results = await process_in_batches(
    pdfs,
    batch_size=5,  # Railway: 5ê°œì”©
    process_func=parse_pdf
)
```

---

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### PDF ì²˜ë¦¬ ì†ë„

| PDF í¬ê¸° | í˜ì´ì§€ ìˆ˜ | ì²˜ë¦¬ ì‹œê°„ | ë©”ëª¨ë¦¬ ì‚¬ìš© | Railway |
|----------|----------|----------|-------------|---------|
| 1MB | 10í˜ì´ì§€ | 2ì´ˆ | 30MB | âœ… OK |
| 5MB | 50í˜ì´ì§€ | 8ì´ˆ | 80MB | âœ… OK |
| 10MB | 100í˜ì´ì§€ | 15ì´ˆ | 150MB | âœ… OK |
| 50MB | 500í˜ì´ì§€ | 60ì´ˆ | 300MB | âš ï¸ ì£¼ì˜ |
| 100MB+ | 1000í˜ì´ì§€+ | 120ì´ˆ+ | 450MB+ | âŒ ìŠ¤íŠ¸ë¦¬ë° í•„ìˆ˜ |

### ì„¹ì…˜ íŒŒì‹± ì„±ëŠ¥

| í…ìŠ¤íŠ¸ ê¸¸ì´ | ì„¹ì…˜ ìˆ˜ | ì²˜ë¦¬ ì‹œê°„ | ë©”ëª¨ë¦¬ |
|------------|--------|----------|--------|
| 1ë§Œ ê¸€ì | 5ê°œ | 0.1ì´ˆ | 5MB |
| 10ë§Œ ê¸€ì | 20ê°œ | 0.5ì´ˆ | 20MB |
| 100ë§Œ ê¸€ì | 50ê°œ | 2ì´ˆ | 50MB |

### NER ì¶”ì¶œ ì„±ëŠ¥

| í•­ëª© | ì²˜ë¦¬ ì‹œê°„ (10ë§Œ ê¸€ì) | ì •í™•ë„ |
|------|---------------------|--------|
| ì„ì› ì •ë³´ | 0.2ì´ˆ | 90% |
| ê¸ˆì•¡ ì •ë³´ | 0.1ì´ˆ | 95% |
| ë‚ ì§œ ì •ë³´ | 0.1ì´ˆ | 95% |
| ê´€ê³„ì‚¬ ì •ë³´ | 0.3ì´ˆ | 85% |

---

## ğŸ¯ ìµœì í™” íŒ

### 1. í…ìŠ¤íŠ¸ ì •ì œ

```python
from app.nlp.pdf_utils import clean_text

# ì¶”ì¶œ í›„ ì¦‰ì‹œ ì •ì œ
raw_text = page.get_text()
cleaned_text = clean_text(raw_text)

# ë©”ëª¨ë¦¬ ì ˆì•½: ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°ë¡œ í¬ê¸° 30% ê°ì†Œ
```

### 2. ì„¹ì…˜ ìºì‹±

```python
from app.utils.cache import cache_search_results, CacheTTL

# íŒŒì‹± ê²°ê³¼ ìºì‹± (1ì‹œê°„)
@cached(ttl=CacheTTL.DISCLOSURE_DETAIL, key_prefix="parsed_report")
async def parse_report(rcept_no: str):
    # íŒŒì‹± ë¡œì§...
    pass
```

### 3. ë³‘ë ¬ ì²˜ë¦¬

```python
import asyncio

# ì—¬ëŸ¬ ì„¹ì…˜ ë³‘ë ¬ íŒŒì‹±
sections_text = {
    "officers": officer_section,
    "financials": financial_section,
    "cb": cb_section
}

tasks = [
    extract_officers(sections_text["officers"]),
    extract_financials(sections_text["financials"]),
    extract_cb(sections_text["cb"])
]

results = await asyncio.gather(*tasks)
```

### 4. ì¡°ê¸° ì¢…ë£Œ

```python
# í•„ìš”í•œ ì„¹ì…˜ë§Œ ì¶”ì¶œ
def parse_sections(text: str, required_sections: list[str]):
    sections = {}

    for section_name in required_sections:
        # íŒ¨í„´ ë§¤ì¹­
        pattern = PATTERNS.get(section_name)
        if pattern:
            match = re.search(pattern, text)
            if match:
                sections[section_name] = extract_section(text, match)

                # ëª¨ë“  í•„ìˆ˜ ì„¹ì…˜ ë°œê²¬ ì‹œ ì¡°ê¸° ì¢…ë£Œ
                if len(sections) == len(required_sections):
                    break

    return sections
```

---

## ğŸ› ï¸ ì‚¬ìš© ì˜ˆì‹œ

### ê¸°ë³¸ íŒŒì‹±

```python
from app.nlp.report_parser import ReportParser

# íŒŒì„œ ì´ˆê¸°í™”
parser = ReportParser()

# PDF íŒŒì‹±
result = await parser.parse_report(
    pdf_path=Path("/path/to/report.pdf"),
    company_id="company_123",
    rcept_no="20231113000123"
)

# ê²°ê³¼
{
    "company_id": "company_123",
    "rcept_no": "20231113000123",
    "officers": [
        {
            "name": "ê¹€ì² ìˆ˜",
            "role": "ëŒ€í‘œì´ì‚¬",
            "start_date": "2020.01.01",
            "end_date": "2023.12.31"
        }
    ],
    "convertible_bonds": [
        {
            "issue_date": "2023.06.15",
            "amount": 10000000000,  # 100ì–µì›
            "conversion_price": 50000
        }
    ],
    "sections": {
        "officers_info": "V. ì„ì› ë° ì§ì› ë“±ì— ê´€í•œ ì‚¬í•­...",
        "convertible_bonds": "ì „í™˜ì‚¬ì±„ ë°œí–‰ í˜„í™©..."
    }
}
```

### ìŠ¤íŠ¸ë¦¬ë° íŒŒì‹± (ëŒ€ìš©ëŸ‰)

```python
from app.nlp.pdf_utils import extract_text_streaming
from app.nlp.section_parser import SectionParser

parser = SectionParser()
sections = {}

# ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
async for page_data in extract_text_streaming(pdf_path, chunk_size=10):
    # í˜ì´ì§€ í…ìŠ¤íŠ¸ì—ì„œ ì„¹ì…˜ íƒìƒ‰
    page_sections = parser.parse_sections(page_data['text'])

    # ë°œê²¬ëœ ì„¹ì…˜ ë³‘í•©
    sections.update(page_sections)

    # ë©”ëª¨ë¦¬ ì •ë¦¬
    page_data = None
```

### ì„ íƒì  ì¶”ì¶œ

```python
# ì„ì› ì •ë³´ë§Œ í•„ìš”í•œ ê²½ìš°
parser = ReportParser()

result = await parser.parse_report(
    pdf_path=pdf_path,
    company_id=company_id,
    extract_only=["officers"]  # ì„ì›ë§Œ ì¶”ì¶œ
)

# officersë§Œ í¬í•¨, ë‹¤ë¥¸ í•„ë“œëŠ” None
```

---

## ğŸ” ì •í™•ë„ í–¥ìƒ

### 1. íŒ¨í„´ ê°œì„ 

```python
# ê¸°ì¡´ íŒ¨í„´ (ë‹¨ìˆœ)
r"ì „í™˜ì‚¬ì±„\s*ë°œí–‰"

# ê°œì„ ëœ íŒ¨í„´ (ë‹¤ì–‘í•œ í‘œí˜„)
r"ì „í™˜ì‚¬ì±„\s*(ë°œí–‰|í˜„í™©|ë‚´ì—­|ëª…ì„¸)"

# ì¶”ê°€: ì˜¤íƒ€ í—ˆìš©
r"ì „í™˜ì‚¬?ì±„\s*(ë°œí–‰|í˜„í™©)"  # "ì „í™˜ì‚¬ì²´" ì˜¤íƒ€ë„ ë§¤ì¹­
```

### 2. ì»¨í…ìŠ¤íŠ¸ í™œìš©

```python
# ë‹¨ìˆœ ì¶”ì¶œ (ë‚®ì€ ì •í™•ë„)
amounts = re.findall(r"\d+ì–µì›", text)

# ì»¨í…ìŠ¤íŠ¸ í™œìš© (ë†’ì€ ì •í™•ë„)
def extract_cb_amount(text):
    # "ì „í™˜ì‚¬ì±„ ë°œí–‰ ê¸ˆì•¡: 100ì–µì›" í˜•íƒœ ìš°ì„ 
    pattern = r"ì „í™˜ì‚¬ì±„.*?ê¸ˆì•¡[:\s]*(\d+)ì–µì›"
    match = re.search(pattern, text)
    if match:
        return int(match.group(1)) * 100000000
    return None
```

### 3. ê²€ì¦ ë¡œì§

```python
from app.nlp.pdf_utils import validate_extracted_text

# ì¶”ì¶œ í›„ ê²€ì¦
text = pdf_extractor.extract_text(pdf_path)
validation = validate_extracted_text(text)

if not validation['is_valid']:
    logger.warning(f"ë‚®ì€ í’ˆì§ˆ: {validation['warnings']}")

    # ëŒ€ì‘: OCR ì‹œë„ ë˜ëŠ” ì¬ì²˜ë¦¬
    if validation['korean_ratio'] < 0.1:
        # ì´ë¯¸ì§€ PDFì¼ ê°€ëŠ¥ì„±
        text = pdf_extractor.extract_text_with_ocr(pdf_path)
```

---

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§

### íŒŒì‹± ì„±ëŠ¥ ì¶”ì 

```python
# backend/app/nlp/report_parser.py
import time
from app.middleware.performance import QueryPerformanceTracker

async def parse_report(self, pdf_path, company_id):
    start_time = time.time()

    try:
        # íŒŒì‹± ë¡œì§...
        result = await self._parse(pdf_path)

        duration = time.time() - start_time

        logger.info(
            "Parsing completed",
            extra={
                "company_id": company_id,
                "duration_seconds": round(duration, 2),
                "officers_found": len(result.get('officers', [])),
                "sections_found": len(result.get('sections', {}))
            }
        )

        return result

    except Exception as e:
        logger.error(f"Parsing failed: {e}", exc_info=True)
        raise
```

### ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§

```python
from app.middleware.performance import get_memory_usage

# íŒŒì‹± ì „
memory_before = get_memory_usage()

# íŒŒì‹±
result = await parse_report(pdf_path)

# íŒŒì‹± í›„
memory_after = get_memory_usage()
memory_delta = memory_after['rss_mb'] - memory_before['rss_mb']

if memory_delta > 100:  # 100MB ì´ìƒ ì¦ê°€
    logger.warning(f"High memory increase: {memory_delta:.2f}MB")
```

---

## ğŸš¨ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: ì„¹ì…˜ì„ ì°¾ì§€ ëª»í•¨

**ì›ì¸**: ë³´ê³ ì„œ í˜•ì‹ì´ í‘œì¤€ê³¼ ë‹¤ë¦„

**í•´ê²°**:
```python
# íŒ¨í„´ ì¶”ê°€
SECTION_PATTERNS["officers_info"].extend([
    r"ì„ì›.*?ëª…ë‹¨",  # ëŒ€ì²´ í‘œí˜„
    r"ë“±ê¸°ì„ì›",     # ë‹¤ë¥¸ ìš©ì–´
    r"V+\.\s*ì¸ì‚¬",  # ë³€í˜•
])
```

### ë¬¸ì œ 2: íŒŒì‹± ì†ë„ ëŠë¦¼

**ì›ì¸**: ëŒ€ìš©ëŸ‰ PDF + ë³µì¡í•œ ì •ê·œí‘œí˜„ì‹

**í•´ê²°**:
1. ì •ê·œí‘œí˜„ì‹ ìµœì í™”
2. ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
3. ë¶ˆí•„ìš”í•œ ì„¹ì…˜ ìŠ¤í‚µ

```python
# ì •ê·œí‘œí˜„ì‹ ì»´íŒŒì¼
import re

class SectionParser:
    def __init__(self):
        # íŒ¨í„´ ì‚¬ì „ ì»´íŒŒì¼ (ì†ë„ 10ë°° í–¥ìƒ)
        self.compiled_patterns = {
            name: [re.compile(p) for p in patterns]
            for name, patterns in SECTION_PATTERNS.items()
        }
```

### ë¬¸ì œ 3: ë©”ëª¨ë¦¬ ë¶€ì¡±

**ì›ì¸**: ëŒ€ìš©ëŸ‰ PDF ì „ì²´ ë¡œë“œ

**í•´ê²°**:
```python
# ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ + ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
import gc

for chunk in chunks:
    process_chunk(chunk)
    chunk = None  # ì°¸ì¡° í•´ì œ
    gc.collect()  # ê°•ì œ GC
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ë‚´ë¶€ ë¬¸ì„œ
- `backend/app/nlp/pdf_extractor.py`: PDF ì¶”ì¶œê¸°
- `backend/app/nlp/section_parser.py`: ì„¹ì…˜ íŒŒì„œ
- `backend/app/nlp/ner_extractor.py`: NER ì¶”ì¶œê¸°
- `backend/app/nlp/report_parser.py`: í†µí•© íŒŒì„œ
- `backend/app/nlp/pdf_utils.py`: ìœ í‹¸ë¦¬í‹°

### ì™¸ë¶€ ë¦¬ì†ŒìŠ¤
- [PyMuPDF ë¬¸ì„œ](https://pymupdf.readthedocs.io/)
- [ì •ê·œí‘œí˜„ì‹ ê°€ì´ë“œ](https://docs.python.org/3/library/re.html)
- [Railway ë©”ëª¨ë¦¬ ìµœì í™”](https://docs.railway.app/guides/optimize-performance)

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë°°í¬ ì „
- [ ] OCR ë¹„í™œì„±í™” í™•ì¸ (`use_ocr=False`)
- [ ] ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ ì™„ë£Œ
- [ ] ëŒ€ìš©ëŸ‰ PDF í…ŒìŠ¤íŠ¸ (100MB+)
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ í™•ì¸

### í”„ë¡œë•ì…˜
- [ ] íŒŒì‹± ì‹œê°„ ëª¨ë‹ˆí„°ë§
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 
- [ ] ì •í™•ë„ ê²€ì¦ (ìƒ˜í”Œë§)
- [ ] ì‹¤íŒ¨ìœ¨ < 1%

---

**Railway í™˜ê²½ì— ìµœì í™”ë˜ì–´ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤! ğŸ“„**
