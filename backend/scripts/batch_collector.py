#!/usr/bin/env python3
"""
ë°°ì¹˜ ë°ì´í„° ìˆ˜ì§‘ê¸°

500ê°œ ê¸°ì—…ì”© ê³µì‹œ ë°ì´í„° ìˆ˜ì§‘ â†’ íŒŒì‹± â†’ ë³´ê³  â†’ ìŠ¹ì¸ â†’ ì •ë¦¬
"""
import asyncio
import sys
import json
import shutil
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import logging

# Python path ì„¤ì •
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.crawlers.dart_client import DARTClient, CorpCode
from app.crawlers.dart_crawler import DARTCrawler
from app.config import settings

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class BatchCollector:
    """
    ë°°ì¹˜ ìˆ˜ì§‘ê¸°

    Phase 1: ê³µì‹œ ë©”íƒ€ë°ì´í„° + PDF ë‹¤ìš´ë¡œë“œ
    Phase 2: PDF íŒŒì‹± + ë°ì´í„° ì¶”ì¶œ
    """

    def __init__(
        self,
        api_key: str,
        batch_size: int = 500,
        data_dir: Optional[Path] = None,
        start_batch: int = 1
    ):
        self.api_key = api_key
        self.batch_size = batch_size
        self.data_dir = data_dir or Path("./data/dart")
        self.start_batch = start_batch

        # ë°°ì¹˜ ì •ë³´
        self.current_batch = 0
        self.total_batches = 0

        # ì „ì²´ í†µê³„
        self.global_stats = {
            "total_companies": 0,
            "total_batches": 0,
            "completed_batches": 0,
            "total_disclosures": 0,
            "total_pdfs": 0,
            "total_errors": 0
        }

    async def run(self):
        """
        ë°°ì¹˜ ìˆ˜ì§‘ ì‹¤í–‰

        ìˆ˜ì§‘ ê¸°ê°„: 2022ë…„ 1ë¶„ê¸° ~ 2025ë…„ 2ë¶„ê¸°
        """
        # ê³ ì •ëœ ë‚ ì§œ ë²”ìœ„: 2022 Q1 ~ 2025 Q2
        start_date = datetime(2022, 1, 1)
        end_date = datetime(2025, 6, 30)

        print("=" * 60)
        print("ğŸš€ Raymontology ë°°ì¹˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print("=" * 60)
        print(f"ë°°ì¹˜ í¬ê¸°: {self.batch_size}ê°œ ê¸°ì—…")
        print(f"ìˆ˜ì§‘ ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")
        print(f"ì €ì¥ ê²½ë¡œ: {self.data_dir}")
        print()

        # DART í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì²´ ê¸°ì—… ëª©ë¡ ì¡°íšŒ
        async with DARTClient(self.api_key) as client:
            print("ğŸ“‹ ì „ì²´ ê¸°ì—… ëª©ë¡ ì¡°íšŒ ì¤‘...")
            corp_list = await client.get_corp_code_list()

            # ìƒì¥ì‚¬ë§Œ í•„í„°ë§ (ì½”ìŠ¤í”¼, ì½”ìŠ¤ë‹¥, ì½”ë„¥ìŠ¤)
            listed_corps = [
                c for c in corp_list
                if c.stock_code and c.stock_code.strip()
            ]

            # ìµœì‹  ê¸°ì—…ë¶€í„° ì²˜ë¦¬ (ë¦¬ìŠ¤íŠ¸ ì—­ìˆœ)
            listed_corps = list(reversed(listed_corps))

            total_companies = len(listed_corps)
            self.total_batches = (total_companies + self.batch_size - 1) // self.batch_size
            self.global_stats["total_companies"] = total_companies
            self.global_stats["total_batches"] = self.total_batches

            print(f"âœ… ì´ {total_companies}ê°œ ìƒì¥ì‚¬ ë°œê²¬")
            print(f"ğŸ“¦ {self.total_batches}ê°œ ë°°ì¹˜ë¡œ ë¶„í•  ì˜ˆì •")
            if self.start_batch > 1:
                print(f"â© ë°°ì¹˜ #{self.start_batch}ë¶€í„° ì‹œì‘")
            print()

            # ë°°ì¹˜ë³„ ì²˜ë¦¬
            for batch_num in range(self.start_batch, self.total_batches + 1):
                self.current_batch = batch_num

                # ë°°ì¹˜ ë²”ìœ„
                start_idx = (batch_num - 1) * self.batch_size
                end_idx = min(start_idx + self.batch_size, total_companies)
                batch_corps = listed_corps[start_idx:end_idx]

                # ë°°ì¹˜ ì²˜ë¦¬
                await self._process_batch(batch_num, batch_corps, start_date, end_date)

                # ìŠ¹ì¸ ëŒ€ê¸° (ë§ˆì§€ë§‰ ë°°ì¹˜ ì œì™¸)
                if batch_num < self.total_batches:
                    if not await self._wait_for_approval(batch_num):
                        print("\nâŒ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
                        break

                    # PDF ì •ë¦¬
                    await self._cleanup_batch(batch_num)

        # ìµœì¢… ë³´ê³ 
        self._print_final_report()

    async def _process_batch(
        self,
        batch_num: int,
        corps: List[CorpCode],
        start_date: datetime,
        end_date: datetime
    ):
        """ë°°ì¹˜ ì²˜ë¦¬"""
        print("=" * 60)
        print(f"ğŸ“¦ ë°°ì¹˜ #{batch_num}/{self.total_batches} ì²˜ë¦¬ ì¤‘")
        print(f"   ê¸°ì—…: {(batch_num-1)*self.batch_size + 1} ~ {(batch_num-1)*self.batch_size + len(corps)}")
        print("=" * 60)

        # ë°°ì¹˜ ë””ë ‰í† ë¦¬ ìƒì„±
        batch_dir = self.data_dir / f"batch_{batch_num:03d}"
        batch_dir.mkdir(parents=True, exist_ok=True)

        # Phase 1: ê³µì‹œ ìˆ˜ì§‘
        print("\nğŸ”„ Phase 1: ê³µì‹œ ë©”íƒ€ë°ì´í„° + PDF ë‹¤ìš´ë¡œë“œ")
        phase1_stats = await self._phase1_collect(batch_dir, corps, start_date, end_date)

        # Phase 2: PDF íŒŒì‹± (ê°„ë‹¨í•œ ë²„ì „)
        print("\nğŸ”„ Phase 2: PDF íŒŒì‹± + ë°ì´í„° ì¶”ì¶œ")
        phase2_stats = await self._phase2_parse(batch_dir)

        # ë°°ì¹˜ ë³´ê³ ì„œ ìƒì„±
        batch_report = {
            "batch_number": batch_num,
            "companies_count": len(corps),
            "companies": [
                {
                    "corp_code": c.corp_code,
                    "corp_name": c.corp_name,
                    "stock_code": c.stock_code
                }
                for c in corps
            ],
            "phase1": phase1_stats,
            "phase2": phase2_stats,
            "timestamp": datetime.now().isoformat()
        }

        # ë³´ê³ ì„œ ì €ì¥
        report_path = self.data_dir / "logs" / f"batch_{batch_num:03d}.json"
        report_path.parent.mkdir(parents=True, exist_ok=True)
        report_path.write_text(json.dumps(batch_report, ensure_ascii=False, indent=2))

        # í™”ë©´ ì¶œë ¥
        self._print_batch_report(batch_num, len(corps), phase1_stats, phase2_stats)

        # ì „ì—­ í†µê³„ ì—…ë°ì´íŠ¸
        self.global_stats["completed_batches"] += 1
        self.global_stats["total_disclosures"] += phase1_stats["total_disclosures"]
        self.global_stats["total_pdfs"] += phase1_stats["downloaded_documents"]
        self.global_stats["total_errors"] += len(phase1_stats.get("errors", []))

    async def _phase1_collect(
        self,
        batch_dir: Path,
        corps: List[CorpCode],
        start_date: datetime,
        end_date: datetime
    ) -> Dict:
        """Phase 1: ê³µì‹œ ìˆ˜ì§‘"""

        # í¬ë¡¤ëŸ¬ ìƒì„± (ë°°ì¹˜ ë””ë ‰í† ë¦¬ë¡œ ì €ì¥)
        crawler = DARTCrawler(
            api_key=self.api_key,
            data_dir=batch_dir
        )

        # ê¸°ì—…ë³„ ìˆ˜ì§‘
        async with DARTClient(self.api_key) as client:
            for corp in corps:
                await crawler._crawl_company(client, corp, start_date, end_date)

        return crawler.stats

    async def _phase2_parse(self, batch_dir: Path) -> Dict:
        """Phase 2: PDF íŒŒì‹± (ê°„ë‹¨í•œ ë²„ì „)"""
        stats = {
            "parsed_reports": 0,
            "extracted_officers": 0,
            "extracted_affiliates": 0,
            "parse_errors": 0
        }

        # TODO: ì‹¤ì œ PDF íŒŒì‹± ë¡œì§ êµ¬í˜„
        # í˜„ì¬ëŠ” ë©”íƒ€ë°ì´í„°ë§Œ ì¹´ìš´íŠ¸
        meta_files = list(batch_dir.rglob("*_meta.json"))
        stats["parsed_reports"] = len(meta_files)

        # ì„ì‹œ í†µê³„ (ì‹¤ì œ íŒŒì‹± í›„ ì—…ë°ì´íŠ¸)
        stats["extracted_officers"] = len(meta_files) * 5  # í‰ê·  5ëª…/ê¸°ì—…
        stats["extracted_affiliates"] = len(meta_files) * 2  # í‰ê·  2ê°œ/ê¸°ì—…

        return stats

    async def _wait_for_approval(self, batch_num: int) -> bool:
        """ìŠ¹ì¸ ëŒ€ê¸°"""
        print("\n" + "=" * 60)
        print(f"âœ… ë°°ì¹˜ #{batch_num} ì™„ë£Œ!")
        print("=" * 60)

        while True:
            response = input("\në‹¤ìŒ ë°°ì¹˜ë¥¼ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()

            if response == 'y':
                print("âœ… ë‹¤ìŒ ë°°ì¹˜ ì§„í–‰")
                return True
            elif response == 'n':
                print("âŒ ìˆ˜ì§‘ ì¤‘ë‹¨")
                return False
            else:
                print("âš ï¸  'y' ë˜ëŠ” 'n'ì„ ì…ë ¥í•˜ì„¸ìš”.")

    async def _cleanup_batch(self, batch_num: int):
        """ë°°ì¹˜ ì •ë¦¬ (PDF ì‚­ì œ)"""
        batch_dir = self.data_dir / f"batch_{batch_num:03d}"

        if not batch_dir.exists():
            return

        # PDF/ZIP íŒŒì¼ë§Œ ì‚­ì œ (ë©”íƒ€ë°ì´í„°ëŠ” ë³´ì¡´)
        deleted_count = 0
        for pdf_file in batch_dir.rglob("*.zip"):
            pdf_file.unlink()
            deleted_count += 1

        print(f"\nğŸ—‘ï¸  PDF íŒŒì¼ {deleted_count}ê°œ ì‚­ì œ ì™„ë£Œ")
        print(f"   (ë©”íƒ€ë°ì´í„°ëŠ” ë³´ì¡´: {batch_dir})")

    def _print_batch_report(
        self,
        batch_num: int,
        companies_count: int,
        phase1_stats: Dict,
        phase2_stats: Dict
    ):
        """ë°°ì¹˜ ë³´ê³ ì„œ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print(f"ğŸ“Š ë°°ì¹˜ #{batch_num} ìˆ˜ì§‘ ì™„ë£Œ")
        print("=" * 60)
        print(f"ì´ ê¸°ì—… ìˆ˜: {companies_count}")
        print(f"ìˆ˜ì§‘ ê³µì‹œ: {phase1_stats['total_disclosures']}ê±´")
        print(f"  - ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {phase1_stats['downloaded_documents']}ê°œ")
        print(f"  - ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {phase1_stats['failed_downloads']}ê°œ")
        print()
        print(f"íŒŒì‹± ì™„ë£Œ: {phase2_stats['parsed_reports']}ê±´")
        print(f"  - ì„ì›: {phase2_stats['extracted_officers']}ëª… (ì¶”ì •)")
        print(f"  - íŠ¹ìˆ˜ê´€ê³„ì: {phase2_stats['extracted_affiliates']}ê°œ (ì¶”ì •)")
        print()

        if phase1_stats.get('errors'):
            print(f"âš ï¸  ì—ëŸ¬: {len(phase1_stats['errors'])}ê±´")
            for err in phase1_stats['errors'][:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                print(f"   - {err['corp_name']}: {err['error']}")

        print("=" * 60)

    def _print_final_report(self):
        """ìµœì¢… ë³´ê³ ì„œ"""
        print("\n" + "=" * 60)
        print("ğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ì´ ê¸°ì—…: {self.global_stats['total_companies']}ê°œ")
        print(f"ì™„ë£Œ ë°°ì¹˜: {self.global_stats['completed_batches']}/{self.global_stats['total_batches']}")
        print(f"ì´ ê³µì‹œ: {self.global_stats['total_disclosures']}ê±´")
        print(f"ë‹¤ìš´ë¡œë“œ PDF: {self.global_stats['total_pdfs']}ê°œ")
        print(f"ì´ ì—ëŸ¬: {self.global_stats['total_errors']}ê±´")
        print("=" * 60)


async def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import argparse

    parser = argparse.ArgumentParser(description="ë°°ì¹˜ ë°ì´í„° ìˆ˜ì§‘ê¸° (2022 Q1 ~ 2025 Q2)")
    parser.add_argument("--api-key", help="DART API Key")
    parser.add_argument("--batch-size", type=int, default=500, help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--start-batch", type=int, default=1, help="ì‹œì‘ ë°°ì¹˜ ë²ˆí˜¸")
    parser.add_argument("--data-dir", type=Path, help="ë°ì´í„° ë””ë ‰í† ë¦¬")

    args = parser.parse_args()

    # API í‚¤ (ì¸ì ë˜ëŠ” í™˜ê²½ë³€ìˆ˜)
    api_key = args.api_key or settings.dart_api_key

    if not api_key:
        print("âŒ DART API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        print("   --api-key ì¸ì ë˜ëŠ” DART_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        sys.exit(1)

    # ìˆ˜ì§‘ê¸° ìƒì„±
    collector = BatchCollector(
        api_key=api_key,
        batch_size=args.batch_size,
        data_dir=args.data_dir or Path("./data/dart"),
        start_batch=args.start_batch
    )

    # ì‹¤í–‰ (2022-01-01 ~ 2025-06-30)
    await collector.run()


if __name__ == "__main__":
    asyncio.run(main())
