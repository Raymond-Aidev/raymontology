#!/usr/bin/env python3
"""
íŠ¹ìˆ˜ê´€ê³„ì/ê³„ì—´ì‚¬ ì •ë³´ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ì—…ë³´ê³ ì„œì—ì„œ ê³„ì—´ì‚¬ ë° ìíšŒì‚¬ ì •ë³´ë¥¼ íŒŒì‹±í•˜ì—¬ DBì— ì €ì¥
"""
import asyncio
import sys
from pathlib import Path
from typing import Dict, List, Set
import logging
import json

# Python path ì„¤ì •
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_
from app.database import AsyncSessionLocal
from app.models.affiliates import Affiliate
from app.models.companies import Company
from app.models.disclosures import Disclosure
from scripts.dart_parser import DARTXMLParser

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class AffiliateCollector:
    """ê³„ì—´ì‚¬ ì •ë³´ ìˆ˜ì§‘ê¸°"""

    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.stats = {
            "total_files": 0,
            "parsed_files": 0,
            "total_affiliates_parsed": 0,
            "affiliates_saved": 0,
            "affiliates_matched": 0,
            "affiliates_unmatched": 0,
            "errors": 0
        }
        self.company_cache: Dict[str, str] = {}  # name -> company_id
        self.unmatched_affiliates: Set[str] = set()

    async def run(self):
        """ê³„ì—´ì‚¬ ì •ë³´ ìˆ˜ì§‘ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸ”— íŠ¹ìˆ˜ê´€ê³„ì/ê³„ì—´ì‚¬ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
        print("=" * 60)

        # 1. íšŒì‚¬ ìºì‹œ ë¡œë“œ
        await self._load_company_cache()

        # 2. ì‚¬ì—…ë³´ê³ ì„œ íŒŒì¼ íŒŒì‹±
        print("\nğŸ“‚ ì‚¬ì—…ë³´ê³ ì„œ íŒŒì¼ íŒŒì‹± ì¤‘...")
        await self._parse_business_reports()

        # 3. ë§¤ì¹­ë˜ì§€ ì•Šì€ ê³„ì—´ì‚¬ ì¶œë ¥
        if self.unmatched_affiliates:
            print(f"\nâš ï¸  ë§¤ì¹­ë˜ì§€ ì•Šì€ ê³„ì—´ì‚¬ ({len(self.unmatched_affiliates)}ê°œ):")
            for name in sorted(list(self.unmatched_affiliates))[:20]:
                print(f"  - {name}")
            if len(self.unmatched_affiliates) > 20:
                print(f"  ... ì™¸ {len(self.unmatched_affiliates) - 20}ê°œ")

        # ìµœì¢… í†µê³„
        self._print_stats()

    async def _load_company_cache(self):
        """íšŒì‚¬ ì •ë³´ ìºì‹œ ë¡œë“œ"""
        print("\nğŸ’¾ íšŒì‚¬ ì •ë³´ ë¡œë”© ì¤‘...")

        async with AsyncSessionLocal() as session:
            result = await session.execute(
                select(Company.id, Company.name, Company.corp_code)
            )
            companies = result.all()

            for company_id, name, corp_code in companies:
                # íšŒì‚¬ëª…ìœ¼ë¡œ ë§¤ì¹­
                self.company_cache[name] = str(company_id)

                # íšŒì‚¬ëª… ë³€í˜•ë„ ìºì‹œ (ì£¼ì‹íšŒì‚¬, (ì£¼) ë“± ì œê±°)
                clean_name = name.replace("ì£¼ì‹íšŒì‚¬", "").replace("(ì£¼)", "").strip()
                if clean_name != name:
                    self.company_cache[clean_name] = str(company_id)

        print(f"  âœ… {len(companies)}ê°œ íšŒì‚¬ ë¡œë“œ ì™„ë£Œ (ìºì‹œ: {len(self.company_cache)}ê°œ í‚¤)")

    async def _parse_business_reports(self):
        """ì‚¬ì—…ë³´ê³ ì„œ íŒŒì¼ë“¤ íŒŒì‹±"""

        # ëª¨ë“  ë°°ì¹˜ ë””ë ‰í† ë¦¬ ìˆœíšŒ
        batch_dirs = sorted([
            d for d in self.data_dir.iterdir()
            if d.is_dir() and d.name.startswith('batch_')
        ])

        for batch_dir in batch_dirs:
            batch_num = int(batch_dir.name.split('_')[1])
            print(f"\n  ë°°ì¹˜ #{batch_num:03d} ì²˜ë¦¬ ì¤‘...")

            # ê° íšŒì‚¬ë³„ ì²˜ë¦¬
            for corp_dir in batch_dir.iterdir():
                if not corp_dir.is_dir():
                    continue

                corp_code = corp_dir.name

                # ê° ì—°ë„ë³„ ì²˜ë¦¬
                for year_dir in corp_dir.iterdir():
                    if not year_dir.is_dir():
                        continue

                    # ZIP íŒŒì¼ ì°¾ê¸° (ë©”íƒ€ë°ì´í„°ì—ì„œ ì‚¬ì—…ë³´ê³ ì„œë§Œ í•„í„°ë§)
                    for meta_file in year_dir.glob("*_meta.json"):
                        try:
                            meta_data = json.loads(meta_file.read_text())

                            # ì‚¬ì—…ë³´ê³ ì„œë§Œ ì²˜ë¦¬ (report_nmì— "ì‚¬ì—…ë³´ê³ ì„œ"ê°€ í¬í•¨ëœ ê²½ìš°)
                            report_nm = meta_data.get("report_nm", "")
                            if "ì‚¬ì—…ë³´ê³ ì„œ" not in report_nm:
                                continue

                            rcept_no = meta_data.get("rcept_no")
                            zip_file = meta_file.parent / f"{rcept_no}.zip"

                            if zip_file.exists():
                                await self._process_file(
                                    zip_file=zip_file,
                                    corp_code=corp_code,
                                    meta_data=meta_data
                                )

                        except Exception as e:
                            logger.error(f"Failed to process {meta_file}: {e}")
                            self.stats["errors"] += 1

            # ë°°ì¹˜ë³„ í†µê³„
            print(f"    íŒŒì‹±: {self.stats['parsed_files']}ê°œ, "
                  f"ê³„ì—´ì‚¬: {self.stats['affiliates_saved']}ê°œ ì €ì¥")

    async def _process_file(self, zip_file: Path, corp_code: str, meta_data: dict):
        """ê°œë³„ íŒŒì¼ ì²˜ë¦¬"""
        self.stats["total_files"] += 1

        try:
            # 1. XML íŒŒì‹±
            parser = DARTXMLParser(zip_file)
            result = parser.parse()

            affiliates_data = result.get('affiliates', [])

            if not affiliates_data:
                return

            self.stats["parsed_files"] += 1
            self.stats["total_affiliates_parsed"] += len(affiliates_data)

            # 2. DBì— ì €ì¥
            async with AsyncSessionLocal() as session:
                # ëª¨íšŒì‚¬ ì°¾ê¸°
                parent_result = await session.execute(
                    select(Company).where(Company.corp_code == corp_code)
                )
                parent_company = parent_result.scalar_one_or_none()

                if not parent_company:
                    logger.warning(f"Parent company not found: {corp_code}")
                    return

                rcept_no = meta_data.get("rcept_no")
                rcept_dt = meta_data.get("rcept_dt")

                for aff_data in affiliates_data:
                    try:
                        affiliate_name = aff_data.name
                        relation_type = aff_data.relation_type

                        # ê³„ì—´ì‚¬ íšŒì‚¬ ë§¤ì¹­
                        affiliate_company_id = self.company_cache.get(affiliate_name)

                        if not affiliate_company_id:
                            # ë§¤ì¹­ ì‹¤íŒ¨ - ì´ë¦„ ì •ë¦¬ í›„ ì¬ì‹œë„
                            clean_name = affiliate_name.replace("ì£¼ì‹íšŒì‚¬", "").replace("(ì£¼)", "").strip()
                            affiliate_company_id = self.company_cache.get(clean_name)

                            if not affiliate_company_id:
                                self.unmatched_affiliates.add(affiliate_name)
                                self.stats["affiliates_unmatched"] += 1
                                # ë§¤ì¹­ ì•ˆ ë˜ì–´ë„ ì €ì¥ (ë‚˜ì¤‘ì— ìˆ˜ë™ ë§¤ì¹­ ê°€ëŠ¥)
                        else:
                            self.stats["affiliates_matched"] += 1

                        # ì¤‘ë³µ ì²´í¬
                        existing_result = await session.execute(
                            select(Affiliate).where(
                                and_(
                                    Affiliate.parent_company_id == parent_company.id,
                                    Affiliate.affiliate_name == affiliate_name,
                                    Affiliate.source_date == rcept_dt
                                )
                            )
                        )
                        existing = existing_result.scalar_one_or_none()

                        if existing:
                            # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì—…ë°ì´íŠ¸
                            existing.affiliate_company_id = affiliate_company_id if affiliate_company_id else existing.affiliate_company_id
                            existing.relationship_type = relation_type
                        else:
                            # ìƒˆë¡œ ìƒì„±
                            affiliate = Affiliate(
                                parent_company_id=parent_company.id,
                                affiliate_company_id=affiliate_company_id,
                                affiliate_name=affiliate_name,
                                relationship_type=relation_type,
                                source_disclosure_id=rcept_no,
                                source_date=rcept_dt,
                            )
                            session.add(affiliate)
                            self.stats["affiliates_saved"] += 1

                    except Exception as e:
                        logger.error(f"Failed to save affiliate {affiliate_name}: {e}")
                        self.stats["errors"] += 1

                # ì»¤ë°‹
                try:
                    await session.commit()
                except Exception as commit_error:
                    logger.error(f"Commit failed for {zip_file}: {commit_error}")
                    await session.rollback()
                    self.stats["errors"] += 1

        except Exception as e:
            logger.error(f"Failed to parse {zip_file}: {e}")
            self.stats["errors"] += 1

    def _print_stats(self):
        """í†µê³„ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ê³„ì—´ì‚¬ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
        print("=" * 60)
        print(f"ì²˜ë¦¬í•œ íŒŒì¼: {self.stats['total_files']:,}ê°œ")
        print(f"íŒŒì‹±ëœ íŒŒì¼: {self.stats['parsed_files']:,}ê°œ")
        print(f"íŒŒì‹±ëœ ê³„ì—´ì‚¬: {self.stats['total_affiliates_parsed']:,}ê°œ")
        print(f"ì €ì¥ëœ ê³„ì—´ì‚¬: {self.stats['affiliates_saved']:,}ê°œ")
        print(f"ë§¤ì¹­ ì„±ê³µ: {self.stats['affiliates_matched']:,}ê°œ")
        print(f"ë§¤ì¹­ ì‹¤íŒ¨: {self.stats['affiliates_unmatched']:,}ê°œ")
        print(f"ì—ëŸ¬: {self.stats['errors']:,}ê±´")
        print("=" * 60)


async def main():
    """ë©”ì¸"""
    import argparse

    parser = argparse.ArgumentParser(description="ê³„ì—´ì‚¬ ì •ë³´ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--data-dir", type=Path, default=Path("./data/dart"), help="ë°ì´í„° ë””ë ‰í† ë¦¬")

    args = parser.parse_args()

    collector = AffiliateCollector(args.data_dir)
    await collector.run()


if __name__ == "__main__":
    asyncio.run(main())
