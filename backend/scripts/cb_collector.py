#!/usr/bin/env python3
"""
ì „í™˜ì‚¬ì±„(CB) ì •ë³´ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ì—…ë³´ê³ ì„œì—ì„œ ì „í™˜ì‚¬ì±„, ì‹ ì£¼ì¸ìˆ˜ê¶Œë¶€ì‚¬ì±„(BW), êµí™˜ì‚¬ì±„(EB) ì •ë³´ë¥¼ íŒŒì‹±í•˜ì—¬ DBì— ì €ì¥
"""
import asyncio
import sys
from pathlib import Path
from typing import Dict, List
import logging
import json
from datetime import datetime

# Python path ì„¤ì •
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_
from app.database import AsyncSessionLocal
from app.models.convertible_bonds import ConvertibleBond
from app.models.companies import Company
from app.models.disclosures import Disclosure
from scripts.dart_parser import DARTXMLParser

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class CBCollector:
    """ì „í™˜ì‚¬ì±„ ì •ë³´ ìˆ˜ì§‘ê¸°"""

    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.stats = {
            "total_files": 0,
            "parsed_files": 0,
            "total_bonds_parsed": 0,
            "bonds_saved": 0,
            "bonds_updated": 0,
            "errors": 0
        }

    async def run(self):
        """ì „í™˜ì‚¬ì±„ ì •ë³´ ìˆ˜ì§‘ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸ’° ì „í™˜ì‚¬ì±„(CB) ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
        print("=" * 60)

        # ì‚¬ì—…ë³´ê³ ì„œ íŒŒì¼ íŒŒì‹±
        print("\nğŸ“‚ ì‚¬ì—…ë³´ê³ ì„œ íŒŒì¼ íŒŒì‹± ì¤‘...")
        await self._parse_business_reports()

        # ìµœì¢… í†µê³„
        self._print_stats()

    async def _parse_business_reports(self):
        """ì‚¬ì—…ë³´ê³ ì„œ íŒŒì¼ë“¤ íŒŒì‹±"""

        # ëª¨ë“  ë°°ì¹˜ ë””ë ‰í† ë¦¬ ìˆœíšŒ
        batch_dirs = sorted([
            d for d in self.data_dir.iterdir()
            if d.is_dir() and d.name.startswith('batch_')
        ])

        for batch_dir in batch_dirs:
            batch_num = int(batch_dir.name.split('_')[1])
            print(f"\n  ë°°ì¹˜ #{batch_num:03d} ì²˜ë¦¬ ì¤‘...")

            # ê° íšŒì‚¬ë³„ ì²˜ë¦¬
            for corp_dir in batch_dir.iterdir():
                if not corp_dir.is_dir():
                    continue

                corp_code = corp_dir.name

                # ê° ì—°ë„ë³„ ì²˜ë¦¬
                for year_dir in corp_dir.iterdir():
                    if not year_dir.is_dir():
                        continue

                    # ZIP íŒŒì¼ ì°¾ê¸° (ë©”íƒ€ë°ì´í„°ì—ì„œ ì‚¬ì—…ë³´ê³ ì„œë§Œ í•„í„°ë§)
                    for meta_file in year_dir.glob("*_meta.json"):
                        try:
                            meta_data = json.loads(meta_file.read_text())

                            # ì‚¬ì—…ë³´ê³ ì„œë§Œ ì²˜ë¦¬
                            report_nm = meta_data.get("report_nm", "")
                            if "ì‚¬ì—…ë³´ê³ ì„œ" not in report_nm:
                                continue

                            rcept_no = meta_data.get("rcept_no")
                            zip_file = meta_file.parent / f"{rcept_no}.zip"

                            if zip_file.exists():
                                await self._process_file(
                                    zip_file=zip_file,
                                    corp_code=corp_code,
                                    meta_data=meta_data
                                )

                        except Exception as e:
                            logger.error(f"Failed to process {meta_file}: {e}")
                            self.stats["errors"] += 1

            # ë°°ì¹˜ë³„ í†µê³„
            print(f"    íŒŒì‹±: {self.stats['parsed_files']}ê°œ, "
                  f"CB: {self.stats['bonds_saved']}ê°œ ì €ì¥")

    async def _process_file(self, zip_file: Path, corp_code: str, meta_data: dict):
        """ê°œë³„ íŒŒì¼ ì²˜ë¦¬"""
        self.stats["total_files"] += 1

        try:
            # 1. XML íŒŒì‹±
            parser = DARTXMLParser(zip_file)
            result = parser.parse()

            bonds_data = result.get('convertible_bonds', [])

            if not bonds_data:
                return

            self.stats["parsed_files"] += 1
            self.stats["total_bonds_parsed"] += len(bonds_data)

            # 2. DBì— ì €ì¥
            async with AsyncSessionLocal() as session:
                # ë°œí–‰ íšŒì‚¬ ì°¾ê¸°
                company_result = await session.execute(
                    select(Company).where(Company.corp_code == corp_code)
                )
                company = company_result.scalar_one_or_none()

                if not company:
                    logger.warning(f"Company not found: {corp_code}")
                    return

                rcept_no = meta_data.get("rcept_no")
                rcept_dt = meta_data.get("rcept_dt")

                for bond_data in bonds_data:
                    try:
                        # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (YYYY-MM-DD)
                        issue_date = None
                        maturity_date = None

                        if bond_data.issue_date:
                            issue_date = self._parse_date(bond_data.issue_date)
                        if bond_data.maturity_date:
                            maturity_date = self._parse_date(bond_data.maturity_date)

                        # ì±„ê¶Œëª… ì¶”ì • (ë°œí–‰ì¼ ê¸°ì¤€)
                        bond_name = f"ì „í™˜ì‚¬ì±„ {issue_date}" if issue_date else "ì „í™˜ì‚¬ì±„"

                        # ì¤‘ë³µ ì²´í¬ (íšŒì‚¬ + ë°œí–‰ì¼ ê¸°ì¤€)
                        existing_result = await session.execute(
                            select(ConvertibleBond).where(
                                and_(
                                    ConvertibleBond.company_id == company.id,
                                    ConvertibleBond.issue_date == issue_date,
                                    ConvertibleBond.source_date == rcept_dt
                                )
                            )
                        )
                        existing = existing_result.scalar_one_or_none()

                        if existing:
                            # ê¸°ì¡´ ë ˆì½”ë“œ ì—…ë°ì´íŠ¸
                            if bond_data.issue_amount:
                                existing.issue_amount = bond_data.issue_amount
                            if bond_data.conversion_price:
                                existing.conversion_price = bond_data.conversion_price
                            if bond_data.conversion_ratio:
                                existing.conversion_ratio = bond_data.conversion_ratio
                            if maturity_date:
                                existing.maturity_date = maturity_date

                            self.stats["bonds_updated"] += 1
                        else:
                            # ìƒˆë¡œ ìƒì„±
                            cb = ConvertibleBond(
                                company_id=company.id,
                                bond_name=bond_name,
                                bond_type="CB",  # ê¸°ë³¸ê°’
                                issue_date=issue_date,
                                maturity_date=maturity_date,
                                issue_amount=bond_data.issue_amount,
                                conversion_price=bond_data.conversion_price,
                                conversion_ratio=bond_data.conversion_ratio,
                                source_disclosure_id=rcept_no,
                                source_date=rcept_dt,
                                status="active"  # ê¸°ë³¸ê°’
                            )
                            session.add(cb)
                            self.stats["bonds_saved"] += 1

                    except Exception as e:
                        logger.error(f"Failed to save CB for {company.name}: {e}")
                        self.stats["errors"] += 1

                # ì»¤ë°‹
                try:
                    await session.commit()
                except Exception as commit_error:
                    logger.error(f"Commit failed for {zip_file}: {commit_error}")
                    await session.rollback()
                    self.stats["errors"] += 1

        except Exception as e:
            logger.error(f"Failed to parse {zip_file}: {e}")
            self.stats["errors"] += 1

    def _parse_date(self, date_str: str) -> str:
        """ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹± (YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜)"""
        try:
            # ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›
            formats = [
                "%Y-%m-%d",
                "%Y.%m.%d",
                "%Y/%m/%d",
                "%Y%m%d"
            ]

            for fmt in formats:
                try:
                    dt = datetime.strptime(date_str.strip(), fmt)
                    return dt.strftime("%Y-%m-%d")
                except ValueError:
                    continue

            return date_str
        except Exception as e:
            logger.error(f"Failed to parse date {date_str}: {e}")
            return date_str

    def _print_stats(self):
        """í†µê³„ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š ì „í™˜ì‚¬ì±„(CB) ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ")
        print("=" * 60)
        print(f"ì²˜ë¦¬í•œ íŒŒì¼: {self.stats['total_files']:,}ê°œ")
        print(f"íŒŒì‹±ëœ íŒŒì¼: {self.stats['parsed_files']:,}ê°œ")
        print(f"íŒŒì‹±ëœ CB: {self.stats['total_bonds_parsed']:,}ê°œ")
        print(f"ì €ì¥ëœ CB: {self.stats['bonds_saved']:,}ê°œ")
        print(f"ì—…ë°ì´íŠ¸ëœ CB: {self.stats['bonds_updated']:,}ê°œ")
        print(f"ì—ëŸ¬: {self.stats['errors']:,}ê±´")
        print("=" * 60)


async def main():
    """ë©”ì¸"""
    import argparse

    parser = argparse.ArgumentParser(description="ì „í™˜ì‚¬ì±„(CB) ì •ë³´ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--data-dir", type=Path, default=Path("./data/dart"), help="ë°ì´í„° ë””ë ‰í† ë¦¬")

    args = parser.parse_args()

    collector = CBCollector(args.data_dir)
    await collector.run()


if __name__ == "__main__":
    asyncio.run(main())
