#!/usr/bin/env python3
"""
ë°°ì¹˜ íŒŒì‹± ìŠ¤í¬ë¦½íŠ¸

ë‹¤ìš´ë¡œë“œí•œ DART ZIP íŒŒì¼ë“¤ì„ íŒŒì‹±í•´ì„œ DBì— ì €ì¥
"""
import asyncio
import sys
from pathlib import Path
from typing import List, Dict
import logging
import json

# Python path ì„¤ì •
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from app.database import AsyncSessionLocal
from app.models.officers import Officer
from app.models.companies import Company
from app.models.disclosures import Disclosure  # Import to resolve relationship
from dart_parser import parse_dart_file

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class BatchParser:
    """ë°°ì¹˜ íŒŒì‹±ê¸°"""

    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.stats = {
            "total_files": 0,
            "parsed_files": 0,
            "total_executives": 0,
            "saved_executives": 0,
            "errors": 0
        }

    async def run(self, start_batch: int = 1, end_batch: int = None):
        """ë°°ì¹˜ íŒŒì‹± ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸ”„ ë°°ì¹˜ íŒŒì‹± ì‹œì‘")
        print("=" * 60)

        # ë°°ì¹˜ ë””ë ‰í† ë¦¬ ì°¾ê¸°
        batch_dirs = sorted([d for d in self.data_dir.iterdir() if d.is_dir() and d.name.startswith('batch_')])

        if end_batch:
            batch_dirs = [d for d in batch_dirs if start_batch <= int(d.name.split('_')[1]) <= end_batch]
        else:
            batch_dirs = [d for d in batch_dirs if int(d.name.split('_')[1]) >= start_batch]

        print(f"ì²˜ë¦¬ ëŒ€ìƒ: {len(batch_dirs)}ê°œ ë°°ì¹˜")
        print()

        for batch_dir in batch_dirs:
            batch_num = int(batch_dir.name.split('_')[1])
            await self._process_batch(batch_num, batch_dir)

        # ìµœì¢… í†µê³„
        self._print_stats()

    async def _process_batch(self, batch_num: int, batch_dir: Path):
        """ë°°ì¹˜ ì²˜ë¦¬"""
        print(f"\nğŸ“¦ ë°°ì¹˜ #{batch_num:03d} ì²˜ë¦¬ ì¤‘...")

        # ì‚¬ì—…ë³´ê³ ì„œ ë° ê°ì‚¬ë³´ê³ ì„œ ZIP íŒŒì¼ ì°¾ê¸° (ë©”íƒ€ë°ì´í„°ì—ì„œ í™•ì¸)
        business_reports = []

        for meta_file in batch_dir.rglob("*_meta.json"):
            try:
                meta_data = json.loads(meta_file.read_text())
                report_nm = meta_data.get("report_nm", "")
                # ì‚¬ì—…ë³´ê³ ì„œ ë˜ëŠ” ê°ì‚¬ë³´ê³ ì„œ (ë‘˜ ë‹¤ ì„ì› ì •ë³´ í¬í•¨)
                if "ì‚¬ì—…ë³´ê³ ì„œ" in report_nm or "ê°ì‚¬ë³´ê³ ì„œ" in report_nm:
                    # _meta.jsonì„ .zipìœ¼ë¡œ ë³€ê²½
                    zip_file = Path(str(meta_file).replace('_meta.json', '.zip'))
                    if zip_file.exists():
                        business_reports.append({
                            "zip_path": zip_file,
                            "corp_code": meta_data["corp_code"],
                            "corp_name": meta_data["corp_name"],
                            "stock_code": meta_data.get("stock_code"),
                            "rcept_no": meta_data["rcept_no"],
                            "rcept_dt": meta_data["rcept_dt"]
                        })
            except Exception as e:
                logger.error(f"Failed to read meta file {meta_file}: {e}")

        print(f"  ë³´ê³ ì„œ: {len(business_reports)}ê±´")

        # íŒŒì‹± ë° ì €ì¥
        batch_stats = {
            "files": len(business_reports),
            "executives": 0,
            "saved": 0
        }

        async with AsyncSessionLocal() as session:
            for report in business_reports:
                self.stats["total_files"] += 1

                try:
                    # ZIP íŒŒì‹±
                    parsed_data = parse_dart_file(report["zip_path"])

                    executives = parsed_data.get("executives", [])
                    batch_stats["executives"] += len(executives)
                    self.stats["total_executives"] += len(executives)

                    # DB ì €ì¥
                    saved_count = await self._save_executives(
                        session,
                        executives,
                        report
                    )

                    batch_stats["saved"] += saved_count
                    self.stats["saved_executives"] += saved_count
                    self.stats["parsed_files"] += 1

                except Exception as e:
                    logger.error(f"Failed to process {report['zip_path']}: {e}")
                    self.stats["errors"] += 1

            # ì»¤ë°‹
            await session.commit()

        print(f"  âœ… ì„ì› {batch_stats['executives']}ëª… ë°œê²¬, {batch_stats['saved']}ëª… ì €ì¥")

    async def _save_executives(
        self,
        session: AsyncSession,
        executives: List,
        report: Dict
    ) -> int:
        """ì„ì› ì •ë³´ ì €ì¥"""
        saved_count = 0

        # íšŒì‚¬ ì°¾ê¸° (stock_code ê¸°ì¤€)
        company = None
        if report.get("stock_code"):
            result = await session.execute(
                select(Company).where(Company.ticker == report["stock_code"])
            )
            company = result.scalar_one_or_none()

        for exec_data in executives:
            try:
                # ë™ì¼ ì´ë¦„ + ì§ìœ„ + íšŒì‚¬ë¡œ ì¤‘ë³µ ì²´í¬ (first() ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ í–‰ í—ˆìš©)
                company_id = company.id if company else None
                result = await session.execute(
                    select(Officer).where(
                        Officer.name == exec_data.name,
                        Officer.position == exec_data.position,
                        Officer.current_company_id == company_id
                    ).limit(1)  # ì²« ë²ˆì§¸ ë ˆì½”ë“œë§Œ ê°€ì ¸ì˜´
                )
                existing = result.scalar_one_or_none()

                if existing:
                    # ì—…ë°ì´íŠ¸ (propertiesì— ìµœì‹  ì •ë³´ ì¶”ê°€)
                    properties = existing.properties or {}
                    properties.update({
                        "gender": exec_data.gender,
                        "birth_year_month": exec_data.birth_year_month,
                        "is_registered": exec_data.is_registered,
                        "is_fulltime": exec_data.is_fulltime,
                        "stock_count": exec_data.stock_count,
                        "ownership_ratio": exec_data.ownership_ratio,
                        "last_updated_from": report["rcept_no"],
                        "last_updated_date": report["rcept_dt"]
                    })
                    existing.properties = properties
                    existing.current_company_id = company.id if company else existing.current_company_id
                else:
                    # ìƒˆë¡œ ìƒì„±
                    officer = Officer(
                        name=exec_data.name,
                        position=exec_data.position,
                        current_company_id=company.id if company else None,
                        properties={
                            "gender": exec_data.gender,
                            "birth_year_month": exec_data.birth_year_month,
                            "is_registered": exec_data.is_registered,
                            "is_fulltime": exec_data.is_fulltime,
                            "stock_count": exec_data.stock_count,
                            "ownership_ratio": exec_data.ownership_ratio,
                            "source_report": report["rcept_no"],
                            "source_date": report["rcept_dt"]
                        }
                    )
                    session.add(officer)

                saved_count += 1

            except Exception as e:
                logger.error(f"Failed to save executive {exec_data.name}: {e}")

        return saved_count

    def _print_stats(self):
        """í†µê³„ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š íŒŒì‹± ì™„ë£Œ í†µê³„")
        print("=" * 60)
        print(f"ì²˜ë¦¬ íŒŒì¼: {self.stats['parsed_files']:,} / {self.stats['total_files']:,}")
        print(f"ë°œê²¬ ì„ì›: {self.stats['total_executives']:,}ëª…")
        print(f"ì €ì¥ ì„ì›: {self.stats['saved_executives']:,}ëª…")
        print(f"ì—ëŸ¬: {self.stats['errors']:,}ê±´")
        print("=" * 60)


async def main():
    """ë©”ì¸"""
    import argparse

    parser = argparse.ArgumentParser(description="ë°°ì¹˜ íŒŒì‹± ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--data-dir", type=Path, default=Path("./data/dart"), help="ë°ì´í„° ë””ë ‰í† ë¦¬")
    parser.add_argument("--start-batch", type=int, default=1, help="ì‹œì‘ ë°°ì¹˜")
    parser.add_argument("--end-batch", type=int, help="ì¢…ë£Œ ë°°ì¹˜")

    args = parser.parse_args()

    parser_instance = BatchParser(args.data_dir)
    await parser_instance.run(args.start_batch, args.end_batch)


if __name__ == "__main__":
    asyncio.run(main())
