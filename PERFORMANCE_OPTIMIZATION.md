# Railway ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ

Raymontologyì˜ Railway í™˜ê²½ ìµœì í™” ì „ëµ ë° êµ¬í˜„ ìƒì„¸

---

## ğŸ“‹ ìµœì í™” ê°œìš”

### Railway Hobby Plan ì œí•œì‚¬í•­
- **ë©”ëª¨ë¦¬**: 512MB
- **CPU**: ê³µìœ  vCPU
- **Database**: PostgreSQL (ì—°ê²° ì œí•œ)
- **Network**: ì œí•œëœ ëŒ€ì—­í­

### ìµœì í™” ëª©í‘œ
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ < 400MB (80% ì´í•˜)
- API ì‘ë‹µ ì‹œê°„ < 200ms (P95 < 1s)
- Database ì—°ê²° íš¨ìœ¨ì  ê´€ë¦¬
- ìºì‹œ íˆíŠ¸ìœ¨ > 80%

---

## ğŸ—„ï¸ 1. Database ì—°ê²° í’€ ìµœì í™”

### ì„¤ì • (backend/app/database.py:28-52)

```python
engine = create_async_engine(
    settings.database_url,
    pool_size=5,           # Railway Hobby ì œí•œ
    max_overflow=10,       # í”¼í¬ ì‹œ ì¶”ê°€ 10ê°œ (ì´ 15ê°œ)
    pool_recycle=3600,     # 1ì‹œê°„ë§ˆë‹¤ ì¬í™œìš©
    pool_timeout=30,       # 30ì´ˆ íƒ€ì„ì•„ì›ƒ
    pool_use_lifo=True,    # LIFO ë°©ì‹ (ìºì‹œ íš¨ìœ¨ì„±)
)
```

### ìµœì í™” í¬ì¸íŠ¸

1. **LIFO (Last-In-First-Out) ì „ëµ**
   - ìµœê·¼ ì‚¬ìš©ëœ ì—°ê²°ì„ ì¬ì‚¬ìš©í•˜ì—¬ ìºì‹œ íš¨ìœ¨ì„± í–¥ìƒ
   - Warm connection í™œìš©

2. **TCP Keepalive**
   - ìœ íœ´ ì—°ê²° ìœ ì§€ë¡œ ì¬ì—°ê²° ì˜¤ë²„í—¤ë“œ ê°ì†Œ
   - Railway ë„¤íŠ¸ì›Œí¬ ì•ˆì •ì„± í–¥ìƒ

3. **Connection Recycling**
   - 1ì‹œê°„ë§ˆë‹¤ ì—°ê²° ì¬í™œìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
   - Long-running connection ë¬¸ì œ í•´ê²°

### ëª¨ë‹ˆí„°ë§

```bash
# ì—°ê²° í’€ ìƒíƒœ í™•ì¸
curl https://your-app.railway.app/api/monitoring/metrics/database

# ì‘ë‹µ ì˜ˆì‹œ
{
  "pool": {
    "size": 5,
    "checked_out": 3,
    "overflow": 2,
    "total_connections": 7
  }
}
```

---

## ğŸš€ 2. Redis ìºì‹± ì „ëµ

### ìºì‹œ TTL ì „ëµ (backend/app/utils/cache.py:22-41)

```python
class CacheTTL:
    COMPANY_INFO = 24 * 60 * 60      # 24ì‹œê°„ (ìì£¼ ë³€í•˜ì§€ ì•ŠìŒ)
    RISK_SCORE = 60 * 60             # 1ì‹œê°„ (ì •ê¸° ì—…ë°ì´íŠ¸)
    COMPANY_SEARCH = 30 * 60         # 30ë¶„ (ê²€ìƒ‰ ê²°ê³¼)
    USER_SESSION = 30 * 60           # 30ë¶„ (ì„¸ì…˜)
    RATE_LIMIT = 60                  # 1ë¶„ (Rate limiting)
```

### ìºì‹± íŒ¨í„´

#### 1. ê¸°ì—… ì •ë³´ ìºì‹±

```python
# ì¡°íšŒ ì‹œ ìºì‹œ ìš°ì„ 
cached = await get_cached_company_info(redis, company_id)
if cached:
    return cached

# ìºì‹œ ë¯¸ìŠ¤ ì‹œ DB ì¡°íšŒ í›„ ìºì‹±
company = await db.get(company_id)
await cache_company_info(redis, company_id, company, CacheTTL.COMPANY_INFO)
```

#### 2. ê²€ìƒ‰ ê²°ê³¼ ìºì‹±

```python
# ê²€ìƒ‰ íŒŒë¼ë¯¸í„°ë¥¼ í•´ì‹œë¡œ ë³€í™˜
cache_key = make_hash_key("search", {
    "query": "ì‚¼ì„±",
    "market": "KOSPI",
    "page": 1
})

# ìºì‹œ ì¡°íšŒ/ì €ì¥
results = await get_cached_search_results(redis, search_params)
```

#### 3. ìºì‹œ ë¬´íš¨í™”

```python
# ê¸°ì—… ë°ì´í„° ì—…ë°ì´íŠ¸ ì‹œ ê´€ë ¨ ìºì‹œ ì‚­ì œ
await invalidate_company_cache(redis, company_id)
# ì‚­ì œë˜ëŠ” íŒ¨í„´:
# - company:{id}
# - risk:{id}
# - disclosure:{id}:*
```

### Redis ì—°ê²° í’€ ìµœì í™”

```python
redis_client = await Redis.from_url(
    settings.redis_url,
    max_connections=50,           # ìµœëŒ€ ì—°ê²° ìˆ˜
    socket_timeout=5,             # 5ì´ˆ íƒ€ì„ì•„ì›ƒ
    retry_on_timeout=True,        # íƒ€ì„ì•„ì›ƒ ì‹œ ì¬ì‹œë„
    health_check_interval=30,     # 30ì´ˆë§ˆë‹¤ í—¬ìŠ¤ì²´í¬
)
```

### ìºì‹œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```bash
curl https://your-app.railway.app/api/monitoring/metrics/cache

# ì‘ë‹µ ì˜ˆì‹œ
{
  "total_keys": 1234,
  "memory_used_mb": 12.5,
  "hit_rate": 0.85,              # 85% íˆíŠ¸ìœ¨
  "connected_clients": 5
}
```

---

## âš¡ 3. API ì‘ë‹µ ìµœì í™”

### Gzip ì••ì¶• (main.py:57)

```python
app.add_middleware(GZipMiddleware, minimum_size=1000)
```

- 1KB ì´ìƒ ì‘ë‹µ ìë™ ì••ì¶•
- í‰ê·  70-80% í¬ê¸° ê°ì†Œ
- Railway ëŒ€ì—­í­ ì ˆì•½

### í˜ì´ì§€ë„¤ì´ì…˜ (backend/app/utils/pagination.py)

```python
class PaginationParams(BaseModel):
    page: int = Field(default=1, ge=1)
    page_size: int = Field(default=20, ge=1, le=50)  # ìµœëŒ€ 50ê°œ
```

**ìµœì í™” ì „ëµ**:
1. ìµœëŒ€ í˜ì´ì§€ í¬ê¸° ì œí•œ (50ê°œ)
2. Offset ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜ (ì‘ì€ ë°ì´í„°ì…‹)
3. Cursor ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜ (ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹)

**ì‚¬ìš© ì˜ˆì‹œ**:

```python
# Offset ê¸°ë°˜ (ì¼ë°˜ ê²€ìƒ‰)
items, total = await paginate(
    session,
    query,
    PaginationParams(page=1, page_size=20)
)

# Cursor ê¸°ë°˜ (ëŒ€ìš©ëŸ‰)
response = CursorPaginatedResponse.create(
    items=results,
    limit=params.limit,
    cursor_field="id"
)
```

### ë¶ˆí•„ìš”í•œ JOIN ì œê±°

**ë¹„íš¨ìœ¨ì **:
```python
# âŒ N+1 ì¿¼ë¦¬ ë¬¸ì œ
companies = await session.execute(select(Company))
for company in companies:
    risk = await session.execute(select(Risk).where(Risk.company_id == company.id))
```

**íš¨ìœ¨ì **:
```python
# âœ… JOIN ì‚¬ìš©
query = (
    select(Company, Risk)
    .join(Risk, Company.id == Risk.company_id)
    .options(selectinload(Company.officers))  # Eager loading
)
```

### ì‘ë‹µ í¬ê¸° ìµœì í™”

```python
# í•„ìš”í•œ í•„ë“œë§Œ ì„ íƒ
query = select(
    Company.id,
    Company.name,
    Company.ticker,
    # ... í•„ìš”í•œ í•„ë“œë§Œ
)

# ë¶ˆí•„ìš”í•œ ê´€ê³„ ë¡œë”© ë°©ì§€
query = query.options(
    noload(Company.disclosures),  # í° ê´€ê³„ëŠ” ë¡œë“œí•˜ì§€ ì•ŠìŒ
    lazyload(Company.officers)
)
```

---

## ğŸ’¾ 4. ë©”ëª¨ë¦¬ ê´€ë¦¬ ìµœì í™”

### íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° (backend/app/utils/streaming.py)

#### ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬

```python
# âŒ ë©”ëª¨ë¦¬ì— ì „ì²´ ë¡œë“œ (512MB íŒŒì¼ = OOM)
with open(large_file, 'rb') as f:
    content = f.read()  # ì „ì²´ ë©”ëª¨ë¦¬ ë¡œë“œ

# âœ… ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
async def stream_file(file_path: Path):
    async with aiofiles.open(file_path, 'rb') as f:
        while chunk := await f.read(CHUNK_SIZE_MEDIUM):
            yield chunk

return StreamingResponse(stream_file(pdf_path))
```

#### ì²­í¬ í¬ê¸° ìµœì í™”

```python
CHUNK_SIZE_SMALL = 8 * 1024      # 8KB (ì‘ì€ íŒŒì¼)
CHUNK_SIZE_MEDIUM = 64 * 1024    # 64KB (ì¤‘ê°„ íŒŒì¼)
CHUNK_SIZE_LARGE = 512 * 1024    # 512KB (í° íŒŒì¼)
```

### ë°°ì¹˜ ì²˜ë¦¬

```python
# 1000ê°œ ê¸°ì—… ë¶„ì„ ì‹œ
results = await process_in_batches(
    companies,
    batch_size=get_optimal_batch_size(
        total_items=len(companies),
        item_size_mb=0.1,  # ê¸°ì—…ë‹¹ 100KB
        max_memory_mb=100  # ìµœëŒ€ 100MB ì‚¬ìš©
    ),
    process_func=analyze_company
)
```

**ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚°**:
- ì „ì²´ í•­ëª© < 100: batch_size = 10
- ì „ì²´ í•­ëª© < 1000: batch_size = 50
- ì „ì²´ í•­ëª© >= 1000: batch_size = 100
- ë©”ëª¨ë¦¬ ê¸°ë°˜: max_memory_mb / item_size_mb

### ë©”ëª¨ë¦¬ ì„ê³„ê°’ ëª¨ë‹ˆí„°ë§

```python
# 400MB ì´ìƒ ê²½ê³  (Railway Hobby: 512MB)
if check_memory_threshold(threshold_mb=400):
    logger.warning("Memory usage exceeds threshold")
    # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
    import gc
    gc.collect()
```

---

## ğŸ“Š 5. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (backend/app/middleware/performance.py)

#### ì‘ë‹µ ì‹œê°„ ì¶”ì 

```python
class PerformanceMonitoringMiddleware:
    async def dispatch(self, request, call_next):
        start_time = time.time()
        response = await call_next(request)
        duration_ms = (time.time() - start_time) * 1000

        # ì‘ë‹µ í—¤ë” ì¶”ê°€
        response.headers["X-Response-Time"] = f"{duration_ms:.2f}ms"

        # ëŠë¦° ìš”ì²­ ê²½ê³  (1ì´ˆ ì´ìƒ)
        if duration_ms > 1000:
            logger.warning(f"Slow request: {request.url.path}")
```

#### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì 

```python
# ìš”ì²­ ì „í›„ ë©”ëª¨ë¦¬ ë³€í™” ì¸¡ì •
memory_before = process.memory_info().rss / 1024 / 1024
# ... ìš”ì²­ ì²˜ë¦¬ ...
memory_after = process.memory_info().rss / 1024 / 1024
memory_delta = memory_after - memory_before

# 50MB ì´ìƒ ì¦ê°€ ì‹œ ê²½ê³ 
if memory_delta > 50:
    logger.warning(f"High memory usage: {memory_delta:.2f}MB")
```

### ëª¨ë‹ˆí„°ë§ API ì—”ë“œí¬ì¸íŠ¸

#### 1. ì¢…í•© í—¬ìŠ¤ ì²´í¬

```bash
curl https://your-app.railway.app/api/monitoring/health

# ì‘ë‹µ
{
  "status": "healthy",
  "databases": {
    "postgresql": {"status": "ok", "latency_ms": 12.3},
    "redis": {"status": "ok", "latency_ms": 1.2},
    "neo4j": {"status": "ok", "latency_ms": 5.6}
  }
}
```

#### 2. ì„±ëŠ¥ ë©”íŠ¸ë¦­

```bash
curl https://your-app.railway.app/api/monitoring/metrics/performance

# ì‘ë‹µ
{
  "endpoints": {
    "/api/companies/search": {
      "request_count": 1234,
      "avg_response_time_ms": 125.5,
      "p95_response_time_ms": 450.2,
      "error_count": 5,
      "error_rate": 0.004
    }
  }
}
```

#### 3. ë©”ëª¨ë¦¬ ìƒíƒœ

```bash
curl https://your-app.railway.app/api/monitoring/metrics/memory

# ì‘ë‹µ
{
  "process": {
    "rss_mb": 256.5,
    "vms_mb": 512.3,
    "percent": 50.1
  },
  "system": {
    "total_mb": 512,
    "available_mb": 255.5,
    "used_mb": 256.5,
    "percent": 50.1
  }
}
```

#### 4. ëŠë¦° ì¿¼ë¦¬

```bash
curl https://your-app.railway.app/api/monitoring/metrics/slow-queries

# ì‘ë‹µ
{
  "total": 5,
  "queries": [
    {
      "timestamp": 1699999999,
      "query_name": "get_companies_with_risk",
      "duration_ms": 1250.5,
      "details": {}
    }
  ]
}
```

#### 5. í™œì„± ì•Œë¦¼

```bash
curl https://your-app.railway.app/api/monitoring/alerts

# ì‘ë‹µ
{
  "total": 2,
  "alerts": [
    {
      "type": "memory",
      "severity": "warning",
      "message": "High memory usage: 425MB",
      "threshold": "400MB"
    },
    {
      "type": "slow_response",
      "severity": "warning",
      "message": "Slow P95 response for /api/companies/search: 1250ms",
      "threshold": "1000ms"
    }
  ]
}
```

---

## ğŸ¯ ì„±ëŠ¥ ëª©í‘œ ë° ë²¤ì¹˜ë§ˆí¬

### API ì‘ë‹µ ì‹œê°„

| ì—”ë“œí¬ì¸íŠ¸ | ëª©í‘œ (P50) | ëª©í‘œ (P95) | ì„ê³„ê°’ |
|----------|-----------|-----------|--------|
| GET /api/companies/{id} | 50ms | 200ms | 500ms |
| GET /api/companies/search | 100ms | 300ms | 1000ms |
| POST /api/risk/analyze | 200ms | 1000ms | 3000ms |
| GET /api/disclosures | 150ms | 500ms | 1500ms |

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

| ìƒíƒœ | ì‚¬ìš©ëŸ‰ | ì¡°ì¹˜ |
|------|--------|------|
| ì •ìƒ | < 300MB | ì—†ìŒ |
| ì£¼ì˜ | 300-400MB | ëª¨ë‹ˆí„°ë§ ê°•í™” |
| ê²½ê³  | 400-450MB | ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ |
| ìœ„í—˜ | > 450MB | ì¬ì‹œì‘ ê³ ë ¤ |

### ìºì‹œ ì„±ëŠ¥

| ë©”íŠ¸ë¦­ | ëª©í‘œ | ìµœì†Œ |
|--------|------|------|
| íˆíŠ¸ìœ¨ | > 80% | 70% |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | < 50MB | < 100MB |
| í‰ê·  ì‘ë‹µ ì‹œê°„ | < 5ms | < 10ms |

### Database ì—°ê²°

| ë©”íŠ¸ë¦­ | ëª©í‘œ | ìµœëŒ€ |
|--------|------|------|
| í™œì„± ì—°ê²° | 3-5ê°œ | 10ê°œ |
| ëŒ€ê¸° ì‹œê°„ | < 10ms | < 100ms |
| ì¿¼ë¦¬ ì‹œê°„ | < 50ms | < 500ms |

---

## ğŸ”§ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë°°í¬ ì „

- [ ] Database ì—°ê²° í’€ ì„¤ì • í™•ì¸ (pool_size=5)
- [ ] Redis ì—°ê²° ì„¤ì • í™•ì¸ (max_connections=50)
- [ ] Gzip ì••ì¶• í™œì„±í™”
- [ ] í˜ì´ì§€ë„¤ì´ì…˜ ìµœëŒ€ í¬ê¸° ì œí•œ (50)
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë¯¸ë“¤ì›¨ì–´ í™œì„±í™”

### ë°°í¬ í›„

- [ ] í—¬ìŠ¤ ì²´í¬ í™•ì¸
- [ ] ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ < 200MB
- [ ] API ì‘ë‹µ ì‹œê°„ ì¸¡ì •
- [ ] ìºì‹œ íˆíŠ¸ìœ¨ í™•ì¸
- [ ] ëŠë¦° ì¿¼ë¦¬ ëª¨ë‹ˆí„°ë§

### ì£¼ê¸°ì  ì ê²€ (ì¼ì¼)

- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ íŠ¸ë Œë“œ
- [ ] API ì—ëŸ¬ìœ¨ < 1%
- [ ] P95 ì‘ë‹µ ì‹œê°„ < 1s
- [ ] ìºì‹œ íˆíŠ¸ìœ¨ > 70%
- [ ] Database ì—°ê²° í’€ ìƒíƒœ

---

## ğŸ“ˆ ì„±ëŠ¥ ê°œì„  ì˜ˆì‹œ

### Before ìµœì í™”

```
ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 480MB (94%)
API ì‘ë‹µ ì‹œê°„ (P95): 2.5s
ìºì‹œ íˆíŠ¸ìœ¨: 30%
Database ì—°ê²°: 20ê°œ (ì˜¤ë²„í”Œë¡œìš°)
ì—ëŸ¬ìœ¨: 5%
```

### After ìµœì í™”

```
ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 320MB (62%)
API ì‘ë‹µ ì‹œê°„ (P95): 450ms
ìºì‹œ íˆíŠ¸ìœ¨: 85%
Database ì—°ê²°: 5-7ê°œ
ì—ëŸ¬ìœ¨: 0.5%
```

### ê°œì„ ìœ¨

- ë©”ëª¨ë¦¬: **33% ê°ì†Œ** âœ…
- ì‘ë‹µ ì‹œê°„: **82% ê°œì„ ** âœ…
- ìºì‹œ íš¨ìœ¨: **183% ì¦ê°€** âœ…
- ì—ëŸ¬ìœ¨: **90% ê°ì†Œ** âœ…

---

## ğŸš¨ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë©”ëª¨ë¦¬ ë¶€ì¡± (OOM)

**ì¦ìƒ**: Railwayì—ì„œ ìë™ ì¬ì‹œì‘

**ì›ì¸**:
- ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ ë©”ëª¨ë¦¬ì— ì „ì²´ ë¡œë“œ
- ìºì‹œ ë¬´ì œí•œ ì¦ê°€
- ë©”ëª¨ë¦¬ ëˆ„ìˆ˜

**í•´ê²°**:
1. íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš©
2. ìºì‹œ TTL ë° maxmemory ì„¤ì •
3. ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
4. ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°

### ëŠë¦° API ì‘ë‹µ

**ì¦ìƒ**: P95 > 1s

**ì›ì¸**:
- N+1 ì¿¼ë¦¬ ë¬¸ì œ
- ìºì‹œ ë¯¸ìŠ¤
- ë¶ˆí•„ìš”í•œ JOIN

**í•´ê²°**:
1. ì¿¼ë¦¬ í”„ë¡œíŒŒì¼ë§
2. Eager loading ì‚¬ìš©
3. ìºì‹œ ì „ëµ ê°œì„ 
4. ì¸ë±ìŠ¤ ì¶”ê°€

### Database ì—°ê²° ë¶€ì¡±

**ì¦ìƒ**: "Too many connections"

**ì›ì¸**:
- ì—°ê²° í’€ í¬ê¸° ë¶€ì¡±
- ì—°ê²° ëˆ„ìˆ˜
- íŠ¸ëœì­ì…˜ ë¯¸ì¢…ë£Œ

**í•´ê²°**:
1. ì—°ê²° í’€ í¬ê¸° ì¡°ì •
2. ì—°ê²° ìë™ ë°˜í™˜ í™•ì¸
3. íŠ¸ëœì­ì…˜ timeout ì„¤ì •
4. ì—°ê²° ëª¨ë‹ˆí„°ë§

---

**Railway í™˜ê²½ì—ì„œ ìµœì ì˜ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ë„ë¡ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸš€**
